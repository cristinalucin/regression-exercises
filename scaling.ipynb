{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0620d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DS imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydataset\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#Modeling and scaling\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#My files\n",
    "import env\n",
    "import wrangle as w\n",
    "import model as m\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb12509",
   "metadata": {},
   "source": [
    "## Exercises: Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get zillow data\n",
    "df =w.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Zillow data\n",
    "df = w.clean_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0527193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values for zillow\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a91a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5c4df",
   "metadata": {},
   "source": [
    "### 1. Apply the scalers we talked about in this lesson to your data and visualize the results for the unscaled and scaled distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bfc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.train_validate_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate my split\n",
    "\n",
    "print(f'train -> {train.shape}')\n",
    "print(f'validate -> {validate.shape}')\n",
    "print(f'test -> {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for scaling by limiting to three features and target\n",
    "columns_to_scale = ['bedrooms', 'bathrooms','area','tax_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making copies for each method\n",
    "train_scaled_minmax = train.copy()\n",
    "train_scaled_standard = train.copy()\n",
    "train_scaled_robust = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dece096",
   "metadata": {},
   "source": [
    "### Looking at this dataset, we want to scale several columns: bedrooms, bathrooms, tax_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e55cc",
   "metadata": {},
   "source": [
    "### Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled_minmax[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46be171",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2d74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train[columns_to_scale], ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled_minmax[columns_to_scale], ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a820ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.bedrooms.head(2))\n",
    "print(train_scaled_minmax.bedrooms.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc57c0",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit and transform on training data\n",
    "train_scaled_standard[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a52382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train[columns_to_scale], ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled_standard[columns_to_scale], ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.bedrooms.head(2))\n",
    "print(train_scaled_standard.bedrooms.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68801bfc",
   "metadata": {},
   "source": [
    "### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robust Scaler\n",
    "scaler = RobustScaler()\n",
    "# Fit and transform on training data\n",
    "train_scaled_robust[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5cd53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize this\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train[columns_to_scale], ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled_robust[columns_to_scale], ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.bedrooms.head(2))\n",
    "print(train_scaled_robust.bedrooms.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81ef92",
   "metadata": {},
   "source": [
    "### 2. Apply the .inverse_transform method to your scaled data. Is the resulting dataset the exact same as the original data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d38c1",
   "metadata": {},
   "source": [
    "### Yes, it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0485b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "original_data = train[['bedrooms']]\n",
    "scaled_data = scaler.fit_transform(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6616f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727609db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(scaled_data)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447daa70",
   "metadata": {},
   "source": [
    "### 3. Read the documentation for sklearn's QuantileTransformer. Use normal for the output_distribution and apply this scaler to your data. Visualize the result of your data scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(n_quantiles=10, random_state=0, output_distribution='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = qt.fit_transform(train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize this\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.hist(qt, ec='black')\n",
    "plt.title('Quantile Transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d57bf1",
   "metadata": {},
   "source": [
    "### 4. Use the QuantileTransformer, but omit the output_distribution argument. Visualize your results. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_no_output = QuantileTransformer(n_quantiles=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_no_output = qt_no_output.fit_transform(train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d281b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize this\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.hist(qt_no_output, ec='black')\n",
    "plt.title('Quantile Transformed no output distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a96c0",
   "metadata": {},
   "source": [
    "### 5. Based on the work you've done, choose a scaling method for your dataset. Write a function within your prepare.py that accepts as input the train, validate, and test data splits, and returns the scaled versions of each. Be sure to only learn the parameters for scaling from your training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d276680",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for modeling\n",
    "\n",
    "#Drop columns not needed for modeling\n",
    "\n",
    "def scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['bedrooms', 'bathrooms', 'area','tax_value'],\n",
    "               return_scaler=False):\n",
    "    '''This function takes in train, validate, test, and outputs scaled data based on\n",
    "    the chosen method (quantile scaling) using the columns selected as the only columns\n",
    "    that will be scaled. This function also returns the scaler object as an array if set \n",
    "    to true'''\n",
    "    # make copies of our original data\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "     # select a scaler\n",
    "    scaler = QuantileTransformer(random_state=123, output_distribution='normal')\n",
    "     # fit on train\n",
    "    scaler.fit(train[columns_to_scale])\n",
    "    # applying the scaler:\n",
    "    train_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(train[columns_to_scale]),\n",
    "                                                  columns=train[columns_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(validate[columns_to_scale]),\n",
    "                                                  columns=validate[columns_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(test[columns_to_scale]),\n",
    "                                                 columns=test[columns_to_scale].columns.values).set_index([test.index.values])\n",
    "    if return_scaler:\n",
    "        return scaler, train_scaled, validate_scaled, test_scaled\n",
    "    else:\n",
    "        return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train_scaled, validate_scaled, test_scaled = scale_data(train, validate, test, return_scaler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9829a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb15bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Min value scaled Bedrooms is : {train_scaled.bedrooms.min()}')\n",
    "print(f' Max value scaled Bedrooms is: {train_scaled.bedrooms.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this function to visualize scalers\n",
    "\n",
    "def visualize_scaler(scaler, df, columns_to_scale, bins=10):\n",
    "    fig, axs = plt.subplots(len(columns_to_scale), 2, figsize=(16,9))\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    for (ax1, ax2), col in zip(axs, columns_to_scale):\n",
    "        ax1.hist(df[col], bins=bins)\n",
    "        ax1.set(title=f'{col} before scaling', xlabel=col, ylabel='count')\n",
    "        ax2.hist(df_scaled[col], bins=bins)\n",
    "        ax2.set(title=f'{col} after scaling with {scaler.__class__.__name__}', xlabel=col, ylabel='count')\n",
    "    plt.tight_layout()\n",
    "#    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27803bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler Applied\n",
    "visualize_scaler(scaler=MinMaxScaler(), \n",
    "                 df=train, \n",
    "                 columns_to_scale=columns_to_scale, \n",
    "                 bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841080f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantileTransformer Applied\n",
    "visualize_scaler(scaler=QuantileTransformer(output_distribution='normal'), \n",
    "                 df=train,\n",
    "                 columns_to_scale=columns_to_scale, \n",
    "                 bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6129d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
